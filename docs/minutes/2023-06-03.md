# 2023/06/03議事録

## 概念設計
* [概念図](https://docs.google.com/presentation/d/1wIjPugkUAdvt_OQIjnh8dUanPGtUBc8qIvgNZuvNX6I/edit?usp=sharing)
* 最終的なゴールが[ROSコントロール](https://control.ros.org/master/index.html)と同じに見える
    * [rt-netのわかりやすい資料](https://rt-net.jp/humanoid/archives/3571)
    * 独自実装では劣化版が完成するリスクがある
    * ROSコントロールは破壊的な変更が頻繁に入る問題がある
* Walk => Kickを流れるようにつなぐのは一旦Out of scope
    * 将来的に行きたいが、アーキテクチャの根本改修が必要
* 1フレームだけスタビライザーをするのはいいのか？
    * 歩行の安定化制御だけやれば勝てる説
    * そこから順番にちょっとだけ良くしていく
    * 歩行の安定化制御を考えるとWalk Pattern GeneratorあたりまでSensor Feedbackは返してもいい？
* 参考資料
    * [人型ロボットの状態推定](https://www.jstage.jst.go.jp/article/jrsj/36/2/36_36_116/_pdf)
    * [アクティブ柔軟関節4脚ロボットの足先力制御](https://www.jstage.jst.go.jp/article/jacc/59/0/59_785/_pdf/-char/ja)

### 歩行制御実装方針
* まずはリアルタイム保証とか考えずに作る
* 次に、何らかのリアルタイムスレッドライブラリ＋カーネルパラメータチューニングを試みて少しでもジッタを減らす。
    * https://qiita.com/harumo11/items/5493dd6436db41763f7d
* 歩行制御と認識系が食い合わないように、コアを固定するなどの対処を行う
    * [参考資料](https://github.com/ros2-realtime-demo/pendulum/blob/149211076ca43a58daaa1b2a7a55fcd8e725a8e9/pendulum_bringup/launch/pendulum_bringup.launch.py#L43-L88)

### OS周り
* OSはUbuntu Serverあたりを採用
* [Dockerでリアルタイム処理](https://tshell.hatenablog.com/entry/2020/01/27/214125)も出来なくはない？らしい

### 自己位置推定周り
1. Lanenetあたりで白線抽出
2. Motion Engineでオドメトリ計算
3. オドメトリ、IMU、白線の観測情報、敵味方識別情報およびゴール位置推定情報をPFで統合
4. あわよくば味方からの情報を統合
5. PFのリセットは、State Monitorが推定している状態よりリセット

参考資料：[KFによる自己位置推定](https://www.amazon.co.jp/%E3%82%AB%E3%83%AB%E3%83%9E%E3%83%B3%E3%83%95%E3%82%A3%E3%83%AB%E3%82%BF%E3%81%AE%E5%9F%BA%E7%A4%8E%E3%81%A8%E5%AE%9F%E8%A3%85-%E8%87%AA%E5%8B%95%E9%81%8B%E8%BB%A2%E3%83%BB%E7%A7%BB%E5%8B%95%E3%83%AD%E3%83%9C%E3%83%83%E3%83%88%E3%83%BB%E9%89%84%E9%81%93%E3%81%B8%E3%81%AE%E5%AE%9F%E8%B7%B5%E3%81%BE%E3%81%A7-%E8%A8%AD%E8%A8%88%E6%8A%80%E8%A1%93%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-%E7%B6%B1%E5%B3%B6-%E5%9D%87/dp/4910558039)


### ロボット間情報共有
ボールの位置 + 自己位置 + 状態

### 認識系
* 白線認識
* ボール認識、ゴールポスト認識
* ロボット認識
    * ロボット認識の後段に敵味方識別ネットワークを追加

[現役時代のボール認識ソースコード](https://github.com/hakuturu583/robocup_packages/blob/master/robocup_object_detector/script/ball_detector.py)

### シミュレーション
* NeRFでCITの練習場を三次元再構成
* point cloud to meshで画像認識を試せるようにする
    * https://research.nvidia.com/labs/toronto-ai/NKSR/
        * https://github.com/nv-tlabs/nksr
    * https://docs.nerf.studio/en/latest/reference/cli/ns_export.html

## OP3技術資料
* https://emanual.robotis.com/docs/en/platform/op3/introduction/
* [XM430-W350](https://www.besttechnology.co.jp/modules/knowledge/?Dynamixel%20XM430-W350)
* [LOGICOOL C920](https://www.amazon.co.jp/%E3%83%AD%E3%82%B8%E3%82%AF%E3%83%BC%E3%83%AB-960-000764-LOGICOOL-HD%E3%83%97%E3%83%AD-%E3%82%A6%E3%82%A7%E3%83%96%E3%82%AB%E3%83%A0/dp/B006JH8T3S)


## HW改善点
### サイズが小さい
ROBOTIS OP3は身長50cm、CIT Brainsのロボットは60cm程度
Kids size leagueの勝率が高いチームのボリュームゾーンは60cm程度

### カメラの接続まわり
USBは断線がめちゃくちゃ起きる
2号機はC1カメラ？

### IMUどうなる？
OpenCRのCPUがディスコンなので、もしかしたらIMU周りは問題が起こるかもしれない

## CIT Brains行ったときにほしいデータ
* 相手の機体のデータいっぱい
    * あればあるだけほしい
    * カメラは本番機に載ってるのと同じのを使いたい
* ロボットの高さに合わせてスマホを動かして取った動画
    * とにかく動く物体を移さない
    * カメラは本番機に載ってるのと同じのを使いたい

## TODO
* 柴田さんに質問
    * OP3のカメラ、モータの型番 by 片岡
* ROBOTIS表敬訪問
    * モーターに負荷をかけて、その応答を見せてもらう by 片岡
* CIT Brains表敬訪問
    * 7/5前後で打診 by 山本さん
